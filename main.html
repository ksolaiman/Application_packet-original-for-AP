<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head><title> Research Statement                                                                                                                              KMA Solaiman</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='main.css' rel='stylesheet' type='text/css' /> 
<meta content='main.tex' name='src' /> 
</head><body><div class='maketitle'>
                                                                                         
                                                                                         
                                                                                         
                                                                                         

<h2 class='titleHead'> Research Statement                                                <a href='https://ksolaiman.github.io/'>KMA Solaiman</a> </h2><div class='author'></div><br />
<div class='date'></div>
   </div>
<!-- l. 3 --><p class='indent'>   Real-world use-cases in data-centric applications (including societal, healthcare, or education) with minimal computational
resources often have an unprecedented influx of unstructured and noisy data from multiple sources and modalities. Extraction
of meaningful information from such heterogenous and changing datasets requires achieving the complementary functionalities
of  <span class='ptmri8t-'>cross-modal matching, scalable data management system (mostly search engines and databases), </span>and <span class='ptmri8t-'>situationally-aware
</span><span class='ptmri8t-'>data recommendation. </span>My research goal is to understand how these functionalities can be achieved by designing interactive
algorithms and robust systems that solve the problem of <span class='ptmb8t-'>situational knowledge on demand in open-world</span>
from multiple forms of information, regardless of whether presented as text, images, videos, audio, or other
modalities, while achieving data-driven and resource-aware <span class='ptmri8t-'>data management </span>and <span class='ptmri8t-'>data integration </span>capabilities.
<br class='newline' />   My later works branched into developing scientific principles to <span class='ptmri8t-'>quantify </span>and <span class='ptmri8t-'>characterize novelty </span>(significant and
unexpected events) <span class='ptmri8t-'>in open-world domains</span>, while creating scalable and efficient AI systems that <span class='ptmri8t-'>react to novelty </span>in those
domains.
</p><!-- l. 1 --><p class='indent'>   Developing intelligent AI systems including situational knowledge recommenders for open-world environments involves
tackling multiple <span class='ptmri8t-'>system design challenges</span>: <a id='x1-2r1'></a><br class='newline' /><span class='ptmb8t-'>(1)</span> <span class='ptmb8t-'>Resource-aware Data Management: </span>Data management systems require a comprehensive understanding of the data
properties, user requirements, and limitations imposed by open-world to achieve optimal performance and scalability for
multimodal data recommendation. Emerging multimodal applications impose challenges for traditional system (hardware and
software) design choices ranging all the way from input (heterogeneous sources, context and modalities) and output
(delivery-on-time, quick throughput and diverse users), changing information needs (knowledge base creation and query), to
computational resources (lack of annotations, domain-specific feature extractors or human resources). For instance, we showed
that transfer learning for fine-grained semantic concept extraction from videos turned out to be ill-suited in large-scale systems
<span class='cite'>[<span class='ptmb8t-'>?</span>]</span>. <a id='x1-3r2'></a> <br class='newline' /><span class='ptmb8t-'>(2)</span> <span class='ptmb8t-'>Data Integration: </span>Data integration from various sources to answer queries over a single view of the data to users, is
confronted with a multitude of heterogeneity issues. These problems arise from differences in data attributes names that hold
similar data <span class='cite'>[<span class='ptmb8t-'>?</span>, <span class='ptmb8t-'>?</span>]</span>, communication problems, and variations in data schema and types <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>. As data volume increases and
the necessity to share existing data intensifies, data integration becomes more prevalent. My first approach for
data integration, EARS, delivers integrated query results over time using a mediation approach and schema
mapping <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>, solving the problem of scalability and quick throughput. The second approach, FemmIR, learns a
co-ordinated graph representation of the data samples comprised of their semantic features to deliver approximate
matches <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>. The third approach, WesJeM, uses Contrastive Learning to embed data-objects and their semantic
properties in a high-dimensional space using higher-level semantic features in a data sample as weak labels <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>,
allowing zero-shot similarity matching and data discovery of multimodal data in open-world environments. <a id='x1-4r3'></a>
<br class='newline' /><span class='ptmb8t-'>(3)</span> <span class='ptmb8t-'>Dealing with Open-world Novelties: </span>To construct intelligent AI systems, it is necessary to adapt to evolving scenarios.
However, conventional AI systems face restrictions when it comes to managing unexpected events or "novelties"
that were not previously seen or modeled. We need to characterize, detect and adapt to novelties at various
stages of the AI life cycle, such as data integration, relevance learning, environment modeling, feature extraction,
and inherent domain properties. Novelty characterization and difficulty estimation is required in a plethora of
AI systems ranging from multimodal information retrieval <span class='cite'>[<span class='ptmb8t-'>?</span>]</span> (distribution change and concept drift), dataset
complexity <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>, to visual (object detection in video and image <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>) and planning domains (games <span class='cite'>[<span class='ptmb8t-'>?</span>]</span> and war).
</p><!-- l. 16 --><p class='indent'>   My work has shown positive results on open societal problems that previously required large-scale human endeavor and
computational resources, such as Missing Person Search <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>, Dataset Complexity Estimation <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>, Search and Rescue in
Disasters <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>, and Medical Triage. The impacts of my work in academia span across diverse areas, including Multimodal
Information Retrieval, Data Discovery, Building Robust AI Agents, and Data Completion, thereby creating a significant
impact.
</p><!-- l. 23 --><p class='indent'>   My research on Novelty Adaptation and Situational Knowledge Delivery has the capability to <span class='ptmb8t-'>transform information
</span><span class='ptmb8t-'>retrieval for everyone by empowering AI systems </span>to promptly and precisely retrieve the information required by users, even
                                                                                         
                                                                                         
in situations where the resources are minimal, data sources are in a state of constant change, and involve various modalities,
interconnections, and predictive arguments.
</p><!-- l. 1 --><p class='indent'>   <span class='ptmbc8t-'>R<span class='small-caps'>ESEARCH</span> P<span class='small-caps'>HILOSOPHY</span>. </span>I believe that the ultimate objective of AI is not just to enhance performance on isolated tasks
but to complement human abilities in solving persistent issues in real world, minimize human labor through responsible action,
harness the power of data for our benefit, and make decisions that have long-lasting positive effects. My work is driven by a
desire to integrate these ideas into a context that prioritizes social good and encourages the consumption and
sharing of healthier information. This involves leveraging multimodal techniques to better understand complex
situations, adapting to different situations, and providing trustworthy and easily understandable information for
humans.
</p><!-- l. 2 --><p class='noindent'>___________ <span class='ptmbc8t-x-x-120'>R<span class='small-caps'>ESOURCE</span> A<span class='small-caps'>WARE</span> D<span class='small-caps'>ATA</span> M<span class='small-caps'>ANAGEMENT </span><span class='small-caps'>FOR</span> M<span class='small-caps'>ULTIMODAL</span> A<span class='small-caps'>PPLICATIONS</span></span>
</p><!-- l. 4 --><p class='indent'>   In designing data management systems for modern applications, such as missing person search, disaster resource
management, triage, and emotion recognition, the focus has shifted to account for data-at-rest and streaming input while
ensuring scalability to handle increasing information needs and data ingestion. To address these challenges, during our
collaboration with local police department and MIT for building Missing-person Query engine <span class='cite'>[<span class='ptmb8t-'>?</span>]</span> and Human-in-the-Loop
Video Querying system <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>, we proposed a novel multimodal knowledge querying system called <span class='ptmb8t-'>SKOD </span>(Situational
Knowledge on Demand) <span class='cite'>[<span class='ptmb8t-'>?</span>, <span class='ptmb8t-'>?</span>]</span>. SKOD leverages entity-centric higher-level semantic concepts (such as objects, object types,
physical relations, e.g., a person wearing blue shirt, time and place of an incident), and the functionalities of distributed systems
and RDBMS to query domain-specific information needs in practical multimodal applications. SKOD was developed in
collaboration with Northrop Grumman, MIT, and CMU and demonstrated at Northrop Grumman TechFest in 2019. The project
has been funded by Northrop Grumman for three consecutive years since 2019, renewing the funding every
year.
</p><!-- l. 15 --><p class='indent'>
</p><!-- l. 16 --><p class='noindent'> <span class='ptmbi8t-x-x-120'>Heterogenous Data Ingestion, Scalability, and Delivery-on-demand</span>
</p><!-- l. 17 --><p class='indent'>   We used Postgres as the backend architecture for both data storage and on-time delivery. Building on top of the RDBMS
allows us to scale to practical data volumes, as well as using the querying interface with query-by-example and
query-by-features dramatically lowers the human costs of multimodal and visual domain search <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>. For consuming data from
heterogeneous sources (both at rest and streaming), I integrated Kafka producers and consumers on top of SKOD <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>. Any
query to the system was formulated and considered as an <span class='ptmri8t-'>incident in real life</span>. For delivery-on-demand from
incomplete modalities, we used Postgres Trigger functionality, which is activated whenever an insert occurs that
matches a certain incident (any matching data). This feature allows us to deliver incomplete information need and
complete it later when new matching data is encountered, while being capable of adapting to changing information
requirements. Queries in SKOD can be both standing queries or one-shot queries. To deal with the changing
requirements, we proposed to build a <span class='ptmbi8t-'>query-drive knowledge base </span>for each user, where all queries can relate to a single
incident. SKOD speeds up the data delivery by storing frequent incidents by caching hot queries, and recently used
data.
</p><!-- l. 35 --><p class='indent'>
</p><!-- l. 36 --><p class='noindent'> <span class='ptmbi8t-x-x-120'>Resource-constrained Feature Extraction</span>
</p><!-- l. 37 --><p class='indent'>   Task-specific querying systems face challenges during the data preparation stage due to low-quality data sets and a lack of
labeled training samples. Although large-scale language models have made significant progress, there exists
very few task-specific attribute extractors for text. Our team addressed these issues in SKOD by implementing
a <span class='ptmri8t-'>priority polling system </span>that selects candidate data samples for feature extraction from videos and images,
instead of immediately processing features for batch inputs. This feature, coupled with trigger functionality,
enables us to provide information needs on-demand and complete them with time. Additionally, we developed a
<span class='ptmb8t-'>cloth-color extractor </span>for videos using common-sense reasoning and color and shape analysis <span class='cite'>[<span class='ptmb8t-'>?</span>]</span> on top of YOLO. To
identify attributes in unstructured text, I propose a model called <span class='ptmb8t-'>HART </span><span class='cite'>[<span class='ptmb8t-'>?</span>]</span>, which solves the problem in two
stages: (i) <span class='ptmb8t-'>candidate sentence identification </span>by transforming the problem into a similarity-search problem using
pre-trained language representation models (SBERT) and lexical knowledge bases, and (ii) <span class='ptmb8t-'>semantic attribute
</span><span class='ptmb8t-'>understanding </span>using syntactic characteristics and lexical meanings of the tokens in the candidate sentences.
This approach can be generalized for any domain and lays the groundwork for intelligent document processing.
</p><!-- l. 1 --><p class='noindent'>___________ <span class='ptmbc8t-x-x-120'>L<span class='small-caps'>ABEL</span>-<span class='small-caps'>EffiCIENT</span> D<span class='small-caps'>ATA</span> I<span class='small-caps'>NTEGRATION </span><span class='small-caps'>AT</span> H<span class='small-caps'>IGHER</span> S<span class='small-caps'>EMANTIC</span> L<span class='small-caps'>EVEL</span></span>
                                                                                         
                                                                                         
</p><!-- l. 3 --><p class='indent'>
</p><!-- l. 3 --><p class='noindent'><span class='ptmbi8t-x-x-120'>View-based Data Integration</span>
</p><!-- l. 5 --><p class='indent'>   Traditional data integration approaches suffer because of heterogeneity among data sources and incomplete modalities.
Machine learning models for multimodal data fusion learn joint representations to exploit complementarity
and redundancy of multiple modalities, but overlooks the information needs based on higher-level semantic
concepts. With the use of Postgres trigger and by using a mediated schema for each queried incident, SKOD
delivers integrated query results over time. Since the number of properties-of-interest are quite moderate, using
similar approach to the <span class='ptmri8t-'>Global as View </span>data integration, I proposed to employ <span class='ptmb8t-'>schema mapping </span>between the
<span class='ptmri8t-'>mediated schema </span>and <span class='ptmri8t-'>local schema </span>from different data sources. The proposed approach, <span class='ptmb8t-'>EARS </span><span class='cite'>[<span class='ptmb8t-'>?</span>]</span> adopts an
entity-relationship-attribute schema for each new data source, and a wrapper is designed to translate the source schemas to the
mediated schema. The queries are translated into conjunctive queries between features among data sources and a
SQL-Join is performed at run-time to integrate all the relevant sources. Using the versatility of Postgres, we achieve
the scalability and speed that is required for time sensitive use-cases, with minimal amount of computational
resources.
</p><!-- l. 8 --><p class='indent'>
</p><!-- l. 8 --><p class='noindent'><span class='ptmbi8t-x-x-120'>Approximate Matching using Graph Representation Learning</span>
</p><!-- l. 9 --><p class='indent'>   While the SQL-JOIN based relational DBMS approach allows a lot of flexibility, it does not utilize the historical knowledge
of previous queries, and cannot perform approximate matching. Considering the sensitivity of some open-world application
domains, it is desirable to search for approximate relevance between different modalities and sources. Motivated
by representation-invariant properties of graph representation models combined with the existing works on
approximate graph matching techniques, I propose <span class='ptmb8t-'>co-ordinated graph representation learning of the data
</span><span class='ptmb8t-'>samples comprised of their semantic features </span><span class='cite'>[<span class='ptmb8t-'>?</span>]</span>, where it learns to approximate a novel Edit distance metric,
<span class='ptmri8t-'>CED</span>, based on the multiplicative comparison of the <span class='ptmri8t-'>Hierarchical Attributed Relational Graph </span>representations.
</p><!-- l. 1 --><p class='noindent'><span class='ptmbi8t-x-x-120'>Weakly Supervised Metric Learning for Cross-Modal Matching</span>
</p><!-- l. 2 --><p class='indent'>   For real-world systems, <span class='ptmri8t-'>data discovery from heterogenous modalities </span>and <span class='ptmri8t-'>explanation of the relevant properties among
</span><span class='ptmri8t-'>similar data objects </span>is of equal importance. Since in these applications, manual annotation is not feasible or they lack
annotation resources, we need alternative supervision techniques for cross-modal matching. Motivated by the advancement in
translation and captioning models (video/audio <span class='zptmcm7y-'>→ </span>text), I propose to embed data-objects and their semantic properties in a high
dimensional embedding space via Contrastive Learning. After extracting the interaction among entity-centric higher-level
semantic features (such as, topics, events, entities, triplets) from texts and other translated modalities, a <span class='ptmri8t-'>data
</span><span class='ptmri8t-'>information network </span>is built by connecting data samples to their features via their interactions. Finally, I construct a
structure-infused representation for the data-objects from all modalities in <span class='ptmb8t-'>WesJeM </span><span class='cite'>[<span class='ptmb8t-'>?</span>]</span>, by jointly embedding
the data samples, the features, and the available similarity labels, in a single space. For learning, I defined a
multi-task learning objective capturing the interaction information, by aligning the representation of the data
samples, defined by their textual content, with the representation of features, based on their common relations.
For open-world environment where data and information-need keep changing, along with the dynamic data
sources, WesJeM opens up the path for <span class='ptmb8t-'>Zero-Shot similarity matching </span>and <span class='ptmb8t-'>Data Discovery </span>of multimodal data.
</p><!-- l. 1 --><p class='noindent'>___________ <span class='ptmbc8t-x-x-120'>A<span class='small-caps'>DAPTION </span><span class='small-caps'>TO</span> O<span class='small-caps'>PEN</span>-<span class='small-caps'>WORLD</span> N<span class='small-caps'>OVELTIES</span></span>
</p><!-- l. 3 --><p class='indent'>   AI systems are often limited by their inability to handle unexpected events that are not part of their training data or
well-defined environments. These significant changes or events are referred to as <span class='ptmb8t-'>‘novelties’ </span>under DARPA SAIL-ON
project, and their characterization and adaptation is critical for real-world applications. To build robust and
intelligent AI systems, I developed novelty characterization and adaptation techniques at various stages, including
data integration and relevance learning, environment modeling, feature extraction, training, and domain or data
level.
</p><!-- l. 5 --><p class='indent'>
</p><!-- l. 5 --><p class='noindent'><span class='ptmbi8t-x-x-120'>Novelty Characterization, Detection, and Difficulty Estimation</span>
</p><!-- l. 6 --><p class='indent'>   I characterized the <span class='ptmb8t-'>novelties encountered in multimodal information retrieval </span>in <span class='cite'>[<span class='ptmb8t-'>?</span>]</span> and proposed how WesJeM can be
adapted for changing data patterns and incomplete or noisy modalities in data integration and relevance learning stage.
                                                                                         
                                                                                         
Moreover, motivated by the information-theoretic approach for difficulty estimation of novelties, I proposed an empirical
framework for novelty characterization and difficulty estimation in <span class='ptmb8t-'>planning domains </span><span class='cite'>[<span class='ptmb8t-'>?</span>]</span>. For a reinforcement-learning based
Monopoly agent, graphically modeling the environment to augment the state and action space allow to integrate graph edit
distance as a novelty difficulty metric.
</p><!-- l. 9 --><p class='noindent'><span class='ptmbi8t-x-x-120'>Robust Feature Extraction with Dataset Augmentation</span>
</p><!-- l. 10 --><p class='indent'>   The efficiency of entity-centric machine learning models in response to novelties depends on the efforts during the model
training, design and data collection stages. We proposed a <span class='ptmb8t-'>novelty generation framework </span><span class='cite'>[<span class='ptmb8t-'>?</span>]</span> at the data preparation stage of
training a model to assure its robustness and reduce the bias. We augmented the original dataset in a domain-agnostic and
budget efficient manner with generated novelties for visual modalities, and improved the <span class='ptmb8t-'>novel object detection </span>performance
with the augmented dataset.
</p><!-- l. 16 --><p class='noindent'><span class='ptmbi8t-x-x-120'>Intrinsic Domain Complexity Estimation for Distributed AI Systems</span>
</p><!-- l. 17 --><p class='indent'>   Understanding of the inherent characteristics of the domain is essential for novelty characterization and
model adaptability. We proposed an <span class='ptmb8t-'>application-independent domain complexity </span>measure for the AI systems
in perception domain <span class='cite'>[<span class='ptmb8t-'>?</span>]</span> using <span class='ptmb8t-'>federated learning as the reference paradigm </span>to handle distributed dataset
operations. Building upon intrinsic dataset properties such as dimensionality, heterogeneity and sparsity for singular
environment, we created a complexity metric <span class='ptmri8t-'>for the distributed environment</span>, showing efficacy for classification task.
</p><!-- l. 1 --><p class='noindent'>___________ <span class='ptmbc8t-x-x-120'>F<span class='small-caps'>UTURE</span> R<span class='small-caps'>ESEARCH</span> A<span class='small-caps'>GENDA</span></span>
</p><!-- l. 2 --><p class='indent'>   Currently, we are experiencing a thrilling era for multimodal information processing and robust AI research since it is
highly supported by the core programs in NSF’s Division of Information and Intelligent Systems (IIS) and by
"Harvesting the Data Revolution (<span class='zptmcm7m-'>HDR</span><sup><span class='zptmcm7t-x-x-74'>2</span></sup>)" idea - second wave of one of the 10 big ideas by NSF for long-term
research.
</p><!-- l. 9 --><p class='indent'>   My <span class='ptmb8t-'>long-term goal </span>is to create intelligent systems that can reason, learn and cooperate with humans to improve the
standard of living by utilizing the vast amounts of data available in the modern era. My focus is to devise new algorithms and
methods that can make a significant impact on society, leverage existing scientific advancements, and address real-world
challenges. To that end, I plan to continue my research on <span class='ptmri8t-'>multimodal data management in real world </span>by approaching from the
following directions:
</p><!-- l. 13 --><p class='indent'>
</p><!-- l. 13 --><p class='noindent'><span class='ptmbi8t-x-x-120'>User Preference Modeling</span>
</p><!-- l. 14 --><p class='indent'>   To complete the life-cycle of <span class='ptmri8t-'>situational knowledge delivery</span>, we still have challenges in modeling user’s information need
in a robust and efficient manner in multiple directions <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>: <a id='x1-5r1'></a>(1) user requirement is not always obvious or explicitly stated,<a id='x1-6r2'></a>
(2) user can be interested in multiple types of events and knowledge bases with varying probabilities,<a id='x1-7r3'></a> (3) 
learning algorithms need to <span class='ptmri8t-'>adapt to changing user preferences with time</span>. I aim to develop novel algorithms
using techniques such as active learning and reinforcement learning that can accurately capture and predict
users’ preferences based on their behavior, interactions, and feedback. Understanding the features that drive user
preferences, and leveraging this knowledge to improve personalized recommendations and user experience, has
applications in education (student advising, classroom teaching), e-commerce, healthcare, etc. To achieve this research
goal, collaborations with researchers in  <span class='ptmb8t-'>human-computer interaction, psychology, and marketing </span>will be
essential.
</p><!-- l. 33 --><p class='noindent'><span class='ptmbi8t-x-x-120'>Explainability and Trustworthiness in Data Recommendation</span>
</p><!-- l. 35 --><p class='indent'>   As the amount of multimodal data generated and consumed by users is increasing, there is a growing need for users to
understand the basis for recommendations <span class='cite'>[<span class='ptmb8t-'>?</span>]</span> and the saliency and trustworthiness of the information being
consumed. This is especially important in sensitive domains such as <span class='ptmri8t-'>healthcare, finance, and legal decision-making</span>
to allow for tracking, cross-checking with social contexts and verification. To achieve this goal, collaboration
across multiple areas is necessary, including <span class='ptmb8t-'>data science, natural language processing, computer vision,
</span><span class='ptmb8t-'>human-computer interaction, and ethics</span>. With this, we can ensure that these models are designed with the user in mind,
taking into account their cognitive and perceptual abilities. This collaboration can also lead to the <span class='ptmri8t-'>development of
</span><span class='ptmri8t-'>ethical guidelines and principles for designing trustworthy systems</span>, ensuring that users’ rights and privacy are
protected.
                                                                                         
                                                                                         
</p><!-- l. 46 --><p class='noindent'><span class='ptmbi8t-x-x-120'>Privacy preserving Data Dissemination and Federated Learning</span>
</p><!-- l. 47 --><p class='indent'>   To address the growing concern over data privacy, particularly in medical and identity contexts, research in
privacy-preserving multimodal data dissemination and federated learning is crucial, as identified in SKOD framework <span class='cite'>[<span class='ptmb8t-'>?</span>]</span>.
Further research to integrate the use of local data processing and remote federation with multimodal machine learning
techniques is needed to ensure this new requirement in information processing, while understanding and formalizing the
resource requirements. Collaboration across various fields such as <span class='ptmb8t-'>information security, statistics, data management, law,
</span><span class='ptmb8t-'>ethics, and public policy </span>is vital to advance research in this area.
</p><!-- l. 58 --><p class='indent'>
</p><!-- l. 58 --><p class='noindent'><span class='ptmbi8t-x-x-120'>Information Completion and Data Democratization</span>
</p><!-- l. 59 --><p class='indent'>   As data becomes increasingly important in all domains, there is a need for new techniques that enable individuals and
organizations to efficiently extract insights from data and complete missing information. To address this challenge, future
research should focus on developing advanced machine learning models that are able to perform well even with
incomplete data, as well as methods for effective data integration and knowledge transfer within organizations.
Collaboration is needed between <span class='ptmb8t-'>machine learning experts, data management specialists, and domain experts
</span><span class='ptmb8t-'>in various fields </span>to achieve a comprehensive and effective solution for data democratization and information
completion.
</p><!-- l. 1 --><p class='indent'>
</p><!-- l. 1 --><p class='noindent'>___________ <span class='ptmbc8t-x-x-120'>C<span class='small-caps'>OLLABORATION </span><span class='small-caps'>AND</span> F<span class='small-caps'>UNDING</span></span>
</p><!-- l. 2 --><p class='indent'>   My future research vision requires collaboration with expert researchers in many fields, including natural language
processing, computer vision, machine learning, data mining, social science, human computer interaction, systems and
databases. I gained extensive expertise in overseeing and directing major projects, encompassing teams of over 12 individuals
and collaborating with various universities and institutions. I led multiple masters and undergraduate students, collaborated
with multiple Ph.D. students and coordinated with 5 professors from different universities to participate in the REALM project.
I am fortunate to have close collaborations with professors from multiple universities and research institutes, such as
Massachusetts Institute of Technology (MIT), University of Michigan (UMichigan), University of Southern
California (USC), Information Sciences Institute (ISI), Institute for Defense Analyses (IDA), University of
Massachusetts (UMass), Middle East Technical University (METU), etc. I also have had the fortune to work closely with
researchers from databases and applications, along with end-users and program managers to conduct interdisciplinary
research. I intend to maintain my current collaborations while actively cultivating new partnerships to advance the
establishment of robust principles that underpin research in multimodal knowledge and novelty in learning
models.
</p><!-- l. 9 --><p class='indent'>   During my Ph.D., my work has been mainly supported by the Northrop Grumman Corporation (NGC), DARPA, ARFL,
and Sandia National Lab. Additionally, I have contributed significantly to the writing of grant proposals, including idea
generation, method design, idea illustration and visual aid creation, such as DARPA ITM project, and DARPA Triage
Challenge. As a future faculty, I will continue to seek funding opportunities in the future from early career fellowships and
various funding agencies (e.g., DARPA, ARL, AFRL, IARPA, NSF, NIH, DOE, DOD) and industries (e.g., NGC, Microsoft,
IBM, Ford, Meta, Google, Intel).
</p>
    
</body> 
</html>