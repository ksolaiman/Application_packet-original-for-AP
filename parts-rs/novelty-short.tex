% \textbf{Dealing with Open-world Novelties: }
\textbf{Uncertainty Management in AI Systems. }
%
% Building intelligent AI systems entail adaptation to changing situations. Traditional AI systems are limited in handling unexpected events or `novelties' that are not part of their training data or well-defined environments. We developed techniques for novelty characterization and adaptation at various stages of AI lifecycle, including data integration, relevance learning, environment modeling, feature extraction, and inherent domain properties. These techniques were applied in three areas: novelty characterization and difficulty estimation, robust feature extraction with dataset augmentation, and intrinsic domain complexity estimation for distributed AI systems. 
% The research proposes empirical frameworks and measures to handle these challenges and improve the performance of AI systems in real-world applications.
%
% To construct intelligent AI systems, it is necessary to adapt to evolving scenarios. However, conventional AI systems face restrictions when it comes to managing unexpected events or "novelties" that were not previously seen or modeled. We need to characterize, detect and adapt to novelties at various stages of the AI life cycle, such as data integration, relevance learning, environment modeling, feature extraction, and inherent domain properties. Novelty characterization and difficulty estimation is required in a plethora of AI systems ranging from multimodal information retrieval \cite{solaiman2022open} (distribution change and concept drift), dataset complexity \cite{solaiman2023domainComplexity}, to visual (object detection in video and image \cite{nesen2021dataset}) and planning domains (games \cite{solaiman2022measurement} and war).
% We have applied these techniques to three main areas, namely: novelty characterization and difficulty estimation, robust feature extraction with dataset augmentation, and intrinsic domain complexity estimation for distributed AI systems.
%
AI systems are still limited in handling unexpected events or \textit{novelties} that are not part of their training data or well-defined environments. As part of the concerted effort of DARPA SAIL-ON, I introduced  techniques for characterizing and adapting to novelties at various stages of the AI life cycle, 
% in perception domain and multimodal applications, 
including data integration, relevance learning, environment modeling, feature extraction, and training. Specifically, my research explored novelties in multimodal information retrieval \cite{solaiman2022open}, object detection models \cite{nesen2021dataset}, intrinsic domain complexity estimation \cite{solaiman2023domainComplexity}, and planning domain \cite{solaiman2022measurement}. The proposed approaches aim to enhance the robustness and adaptability of AI systems, enabling them to handle diverse real-world scenarios more effectively. \cite{solaiman2022open} characterized \textbf{novelties in multimodal information retrieval} for the first time in terms of distribution change and concept drift, and showed how WesJeM can adapt to it. \cite{solaiman2023domainComplexity} proposed an \textbf{intrinsic domain complexity measurement} for the distributed environment using federated learning as the reference paradigm.

% This research focuses on addressing the limitations of AI systems in handling unexpected events or novelties that are not part of their training data or well-defined environments. The study introduces novel techniques for characterizing and adapting to novelties at various stages of the AI life cycle, including data integration, relevance learning, environment modeling, feature extraction, and training. Specifically, the research explores novelties in multimodal information retrieval, entity-centric feature extraction models, intrinsic domain complexity measurement, and planning domain novelty estimation. The proposed approaches aim to enhance the robustness and adaptability of AI systems, enabling them to handle diverse real-world scenarios more effectively.